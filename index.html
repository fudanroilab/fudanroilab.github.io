---
title: Lab of Robotics Oriented Intelligence - Fudan University
labNameBig: Lab of Robotics Oriented Intelligence 
labNameSmall: Academy for Engineering & Technology, School of Computer Science, Fudan University
labNameDescript: Let intelligent robots enter our lives
layout: default
color: 	Black
---
<section>

    <!--Swiper-->
    <div class="swiper-container swiper-slider" data-autoplay="5000" data-slide-effect="fade" data-loop="false">
        <div class="jumbotron text-center">
            <h1><font color="{{page.color}}">{{ page.labNameBig }}</font></h1>
            <hr>
            <h3><font color="{{page.color}}">{{ page.labNameSmall }}</font></h3>
            <p class="big"><em><font color="{{page.color}}">{{ page.labNameDescript }}</font></em> </p>

        </div>
        <!-- <div class="swiper-wrapper"> 
            <div class="swiper-slide" data-slide-bg="images/fudan/chunyi.jpg">
                <div class="swiper-slide-caption"></div>
            </div>
            <div class="swiper-slide" data-slide-bg="images/fudan/xianghuitang.jpg">
                <div class="swiper-slide-caption"></div>
            </div>
            <div class="swiper-slide" data-slide-bg="images/fudan/zibinyuan.jpg">
                <div class="swiper-slide-caption"></div>
            </div>
        </div> -->
        <div class="swiper-wrapper"> 
            <div class="swiper-slide" data-slide-bg="images/header-1.jpg">
                <div class="swiper-slide-caption"></div>
            </div>
            <div class="swiper-slide" data-slide-bg="images/header-3.jpg">
                <div class="swiper-slide-caption"></div>
            </div>
            <div class="swiper-slide" data-slide-bg="images/header-4.jpg">
                <div class="swiper-slide-caption"></div>
            </div>
        </div>
    </div>
</section>


<main class="page-content">
    <section class="well well-inset-2">
        <div class="container">
            <h1 class="text-center font-weight-bold">Recent News</h1>
            <div class="row justify-content-center">
                <div class="col-10">
                    <article class="card card-custom card-corporate">
                        <div class="card-header" role="tab">
                            <div class="card-title" id="recent-news-container">  
                                <!-- 显示最近10条新闻 -->
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [March 2025] Our paper "<b>A Survey on RGB, 3D, and Multimodal Approaches for Unsupervised Industrial Image Anomaly Detection</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">Information Fusion (SCI Q1, IF=14.8)</span>! 
                                    <div class="card-arrow"></div>
                                </a>

                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [February 2025] Our paper "<b>D2SP: Dynamic Dual-Stage Purification Framework for Dual Noise Mitigation in Vision-based Affective Recognition</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">CVPR 2025 (CCF A)</span>! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [February 2025] Our paper "<b>Self-supervised video object segmentation via pseudo label rectification</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">Pattern Recognition (SCI Q1, IF=7.5)</span>! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [January 2025] Two papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">ICRA 2025</span> (CCF B) ! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [December 2024] Our paper "<b>Enhancing Environmental Robustness in Few-shot Learning via Conditional Representation Learning</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">IEEE Transactions on Image Processing (SCI Q1, IF=10.94)</span>! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [December 2024] Two papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">AAAI 2025</span> (CCF A) ! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [September 2024] Three papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">NeurIPS 2024</span> (CCF A) ! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [July 2024] We won <span style="color:#FF0000;font-weight:bold;"> the first place</span> in <span style="color:#FF0000;font-weight:bold;">CVPR 2024 Workshop Challenge: Black-box Adversarial Attacks on Vision Foundation Models</span>! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [July 2024] Six papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">ACMMM 2024</span> (CCF A) ! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [July 2024] Our paper "<b>Boosting the Transferability of Adversarial Attacks with Global Momentum Initialization</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">Expert Systems With Applications (SCI Q1, IF=7.5)</span>! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [July 2024] Three papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">ECCV 2024</span> (CCF B) ! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [February 2024] Three papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">CVPR 2024</span> (CCF A) ! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [February 2024] Our paper "<b>MGR3Net: Multigranularity Region Relation Representation Network for Facial Expression Recognition in Affective Robots</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">IEEE Transactions on Industrial Informatics (SCI Q1, IF=12.3)</span>! 
                                    <div class="card-arrow"></div>
                                </a>
                                
                                <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                    [December 2023] Two papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">AAAI 2024</span> (CCF A) ! 
                                    <div class="card-arrow"></div>
                                </a>

                                <!-- 显示更多按钮 -->
                                <div class="text-center mt-3">
                                    <button id="show-more-news" class="btn btn-outline-primary rounded-pill px-4" onclick="toggleNewsVisibility()">Show more</button>
                                </div>
                                
                                <!-- 隐藏的新闻部分 -->
                                <div id="more-news" style="display: none;">
                                    
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [November 2023] Our paper "<b>MSC-AD: A Multi-Scene Unsupervised Anomaly Detection Dataset for Small Defect Detection of Casting Surface</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">IEEE Transactions on Industrial Informatics (SCI Q1, IF=12.3)</span>! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [September 2023] Two papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">NeurIPS 2023</span> (CCF A) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [July 2023] Six papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">ACMMM 2023</span> (CCF A) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [July 2023] Our paper "<b>Query-Efficient Decision-based Black-Box Patch Attack</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">IEEE Transactions on Information Forensics & Security (CCF A, SCI Q1, IF=6.80)</span>! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [July 2023] Three papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">ICCV 2023</span> (CCF A) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [April 2023] Our paper "<b>Memory Network with Pixel-level Spatio-Temporal Learning for Visual Object Tracking</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">IEEE Transactions on Circuits and Systems for Video Technology (CCF B, SCI Q1, IF=5.89)</span>! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [March 2023] Three papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">CVPR 2023</span> (CCF A) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [February 2023] Our paper "<b>Go Closer To See Better: Camouflaged Object Detection via Object Area Amplification and Figure-ground Conversion</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">IEEE Transactions on Circuits and Systems for Video Technology (CCF B, SCI Q1, IF=5.89)</span>! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [February 2023] Our paper "<b>ADPL: Adaptive Dual Path Learning for Domain Adaptation of Semantic Segmentation</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">IEEE Transactions on Pattern Analysis and Machine Intelligence (CCF A, SCI Q1 Top, IF=24.31)</span>! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false" href="https://mp.weixin.qq.com/s/RVF7b5YH0A7vUgeKwluYAQ">
                                        [December 2022] Dr. Gao Shuyong's paper "<b>CRRNet: Channel Relation Reasoning Network for Salient Object Detection</b>" was selected as <span style="color:#FF0000;font-weight:bold;">the best paper </span> at CCF 2022 China Academic Annual Conference on Intelligent Robotics! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false" href="https://mp.weixin.qq.com/s/RVF7b5YH0A7vUgeKwluYAQ">
                                        [December 2022] Liang Yuanzhi's paper "<b>A knowledge-guided Method for Disease Prediction based on Attention Mechanism</b>" was awarded as <span style="color:#FF0000;font-weight:bold;">the excellent paper </span> in Web Information Systems and Applications (WISA 2022)! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false" href="https://mp.weixin.qq.com/s/RVF7b5YH0A7vUgeKwluYAQ">
                                        [December 2022] Our paper "<b>Dual Cross-Attention for Video Object Segmentation via Uncertainty Refinement</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">IEEE Transactions on Multimedia (CCF B, IF=8.18)</span>! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [November 2022] One paper in the laboratory was accepted by <span style="color:#FF0000;font-weight:bold;">AAAI 2022</span> (CCF A) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false" href="https://mp.weixin.qq.com/s/RVF7b5YH0A7vUgeKwluYAQ">
                                        [October 2022] Our paper "<b>Adaptive Online Mutual Learning Bi-decoders for Video Object Segmentation</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">IEEE Transactions on Image Processing (CCF A, IF=11.04)</span>! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [July 2022] One paper in the laboratory was accepted by <span style="color:#FF0000;font-weight:bold;">ECCV 2022</span> (CCF B) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [June 2022] Two papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">ACMMM 2022</span> (CCF A) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [May 2022] One paper in the laboratory was accepted by <span style="color:#FF0000;font-weight:bold;">Journal of Web Semantics</span> (CCF B) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [April 2022] One paper in the laboratory was accepted by <span style="color:#FF0000;font-weight:bold;">IJCAI 2022</span> (CCF A) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [March 2022] Our paper "<b>A Systematic Review on Affective Computing: Emotion Models, Databases, and Recent Advances</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">Information Fusion (SCI Q1, IF=12.975)</span>! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [March 2022] One paper in the laboratory was accepted by <span style="color:#FF0000;font-weight:bold;">ICME 2022</span> (CCF B) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [March 2022] Three papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">CVPR 2022</span> (CCF A) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [January 2022] Four papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">ICASSP 2022</span> (CCF B) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [January 2022] Congratulations to <b>Xuening Wu</b>, a member of our laboratory, for being elected as the representative of the People's Congress of Xiaoshan District, Hangzhou</span>! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [December 2021] Our paper "<b>Adaptive Selection of Reference Frames for Video Object Segmentation</b>" was accepted by <span style="color:#FF0000;font-weight:bold;">IEEE Transactions on Image Processing (CCF A, IF=9.34)</span>! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [November 2021] Two papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">AAAI 2022</span> (CCF A) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [July 2021] Three papers in the laboratory were accepted by <span style="color:#FF0000;font-weight:bold;">ICCV 2021</span>  (CCF A) ! 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false" href="https://arxiv.org/pdf/2105.06086.pdf">
                                        [May 2021] Lab members participated in the <span style="color:#FF0000;font-weight:bold;">CVPR 2021 Workshop</span> to win the <span style="color:#FF0000;font-weight:bold;">1st place</span> on the NTIRE 2021 Image Deblurring Challenge - Track2! <font class="text-primary">More details</font>. 
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false">
                                        [April 2021] Lab members participated in the <span style="color:#FF0000;font-weight:bold;">CVPR 2021 Workshop</span> to win two-track <span style="color:#FF0000;font-weight:bold;">Top-10</span>! Adversarial Attack on White-box Defense Model (9/1681) and Imagenet Unlimited Adversarial Attack (10/1553).
                                        <div class="card-arrow"></div>
                                    </a>
                                    
                                    {% for post in site.posts %}
                                    {% if post.title == 'Defect Detection Artificial Intelligence National Major Project Weifang Investigation' %}
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false" href="{{ post.url }}">
                                        [September 2020] The laboratory members had an investigation in Weifang for Defect Detection Artificial Intelligence National Major Project! <font class="text-primary">More details</font>.
                                        <div class="card-arrow"></div>
                                    </a>
                                    {% endif %}
                                    {% if post.title == 'The laboratory "Chinese medicine assistant robot" won the silver prize at the 46th Geneva International Invention Exhibition!' %}
                                    <a role="button" class="collapsed" aria-controls="accordion1Collapse1" aria-expanded="false" href="{{ post.url }}">
                                        [April 2018] The laboratory "Chinese medicine assistant robot" won the silver prize at the 46th Geneva International Invention Exhibition! Check out here for <font class="text-primary">more details</font>.
                                        <div class="card-arrow"></div>
                                    </a>
                                    {% endif %}
                                    {% endfor %}
                                    
                                    <!-- 显示更少按钮 -->
                                    <div class="text-center mt-3">
                                        <button id="show-less-news" class="btn btn-outline-primary rounded-pill px-4" onclick="toggleNewsVisibility()">Show less</button>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </article>
                </div>
            </div>
        </div>
    </section>

    <section class="well well-sm well-inset-2">
        <div class="container">
            <h1 class="text-center font-weight-bold">Datasets</h1>
            <div class="row justify-content-center">
                <div class="col-10">


                    <div class="dataset-card">
                        <h3 class="dataset-title text-center mb-4">
                            <span class="dataset-name">LVOS: A Benchmark for Large-scale Long-term Video Object Segmentation <span style="color:#1E88E5; font-style:italic; font-weight:bold;">—— ICCV 2023</span></span>
                        </h3>
                        
                        <div class="text-center mb-4">
                            <img src="images/datasets/LVOS.jpg" alt="LVOS Dataset" class="img-fluid rounded shadow dataset-image">
                        </div>
                        
                        <div class="dataset-contact mt-4">
                            <div class="row align-items-center">
                                <div class="col-md-8 text-left">
                                    <div style="white-space: nowrap; overflow-x: auto;">
                                        <strong class="mr-2">Contact for Access:</strong>
                                        <a href="mailto:lyhong22@m.fudan.edu.cn" class="mr-2">lyhong22@m.fudan.edu.cn</a>
                                        <a href="mailto:weizh@fudan.edu.cn" class="mr-2">weizh@fudan.edu.cn</a>
                                        <a href="mailto:wqzhang@fudan.edu.cn">wqzhang@fudan.edu.cn</a>
                                    </div>
                                </div>
                                <div class="col-md-4 text-md-right">
                                    <a href="https://arxiv.org/pdf/2404.19326" target="_blank" class="btn btn-paper">Paper</a>
                                    <a href="https://lingyihongfd.github.io/lvos.github.io/" target="_blank" class="btn btn-github">
                                        <i class="fa fa-github mr-1"></i> GitHub
                                    </a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="dataset-card">
                        <h3 class="dataset-title text-center mb-4">
                            <span class="dataset-name">FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos <span style="color:#1E88E5; font-style:italic; font-weight:bold;">—— CVPR 2022</span></span>
                        </h3>
                        
                        <div class="text-center mb-4">
                            <img src="images/datasets/FERV39k.png" alt="FERV39k Dataset" class="img-fluid rounded shadow dataset-image">
                        </div>
                        
                        <div class="dataset-contact mt-4">
                            <div class="row align-items-center">
                                <div class="col-md-8 text-left">
                                    <strong class="mr-2">Contact for Access:</strong>
                                    <a href="mailto:yanwang19@fudan.edu.cn">yanwang19@fudan.edu.cn</a>
                                    <a href="mailto:wqzhang@fudan.edu.cn">wqzhang@fudan.edu.cn</a>
                                </div>
                                <div class="col-md-4 text-md-right">
                                    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_FERV39k_A_Large-Scale_Multi-Scene_Dataset_for_Facial_Expression_Recognition_in_CVPR_2022_paper.pdf" target="_blank" class="btn btn-paper">Paper</a>
                                    <a href="https://github.com/wangyanckxx/FERV39k" target="_blank" class="btn btn-github">
                                        <i class="fa fa-github mr-1"></i> GitHub
                                    </a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="well well-sm well-inset-2 text-center text-lg-left">
        <div class="container">
            <h1 class="font-weight-bold text-center">Recent Reports</h1>
            <div class="row row-30">
                <div class="col-lg-6">
                    <article class="thumbnail thumbnail-6 ">
                        <iframe src="//player.bilibili.com/player.html?isOutside=true&aid=114273107838341&bvid=BV1jAZUYEEAj&cid=29213527839&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=300 width=100%> </iframe>
                        <!-- <iframe src="//player.bilibili.com/player.html?isOutside=true&aid=114273107838341&bvid=BV1jAZUYEEAj&cid=29213527839&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe> -->
                        <div class="caption">
                            <h4><a>The Future of Tactile Dexterous Hand Grasping Robots</a></h4> <p class="text-dark-variant-2">Bin Fang, Beijing University of Posts and Telecommunications</p>
                            <div class="blog-info">
                                <div class="pull-md-left">
                                    <time class="meta fa-calendar" datetime="2025">2025 03</time>
                                </div><a class="button-link" href="https://www.bilibili.com/video/BV1jAZUYEEAj/?spm_id_from=333.1387.upload.video_card.click&vd_source=a71531be7fa6f337defc4f86ae7d7865">Read More</a>
                            </div>
                        </div>
                    </article>
                </div>
                <div class="col-lg-6">
                    <article class="thumbnail thumbnail-6 ">
                        <iframe src="//player.bilibili.com/player.html?isOutside=true&aid=114403148041469&bvid=BV1XsLdzqEdh&cid=29621813633&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=300 width=100%> </iframe>
                        <!-- <iframe src="//player.bilibili.com/player.html?isOutside=true&aid=114273107838341&bvid=BV1jAZUYEEAj&cid=29213527839&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe> -->
                        <div class="caption">
                            <h4><a>Progress in the Design of Tactile and Visual Sensors for Dexterous Manipulation</a></h4> <p class="text-dark-variant-2">Jieji Ren, Shanghai Jiao Tong University</p>
                            <div class="blog-info">
                                <div class="pull-md-left">
                                    <time class="meta fa-calendar" datetime="2025">2025 04</time>
                                </div><a class="button-link" href="https://www.bilibili.com/video/BV1XsLdzqEdh/?share_source=copy_web&vd_source=baf456bcfe34c4556c258d2cfd1215da">Read More</a>
                            </div>
                        </div>
                    </article>
                </div>
                
            </div>

            <div class="row row-30">
                <div class="col-lg-6">
                    <article class="thumbnail thumbnail-6 ">
                        <iframe src="//player.bilibili.com/player.html?isOutside=true&aid=114403299036278&bvid=BV1ANLdzHEEH&cid=29622405413&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=300 width=100%> </iframe>
                        <div class="caption">
                            <h4><a>Visual navigation based on self-supervised learning of differentiable physics</a></h4> <p class="text-dark-variant-2">Danping Zou, Shanghai Jiao Tong University</p>
                            <div class="blog-info">
                                <div class="pull-md-left">
                                    <time class="meta fa-calendar" datetime="2025">2025 04</time>
                                </div><a class="button-link" href="https://www.bilibili.com/video/BV1ANLdzHEEH/?vd_source=a71531be7fa6f337defc4f86ae7d7865">Read More</a>
                            </div>
                        </div>
                    </article>
                </div>

                
            </div>
            <!-- <div class="row row-30">
                <div class="col-lg-6">
                    <article class="thumbnail thumbnail-6 ">
                        <iframe src="//player.bilibili.com/player.html?aid=298513755&bvid=BV1jF411u7GY&cid=584853786&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=300 width=100%> </iframe>
                        <div class="caption">
                            <h4><a>Visual SLAM for Device-Cloud Collaboration</a></h4> <p class="text-dark-variant-2">Guofeng Zhang, Zhejiang University</p>
                            <div class="blog-info">
                                <div class="pull-md-left">
                                    <time class="meta fa-calendar" datetime="2022">2022 04</time>
                                </div><a class="button-link" href="https://www.bilibili.com/video/BV1jF411u7GY?spm_id_from=333.999.0.0">Read More</a>
                            </div>
                        </div>
                    </article>
                </div>
                <div class="col-lg-6">
                    <article class="thumbnail thumbnail-6">
                        <iframe controls src="//player.bilibili.com/player.html?aid=426055926&bvid=BV1E3411K7MR&cid=584856458&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=300 width=100%> </iframe>
                        <div class="caption">
                            <h4><a>Visual SLAM in Complex Urban Environments</a></h4> <p class="text-dark-variant-2">Danping Zou, Shanghai Jiao Tong University</p>
                            <div class="blog-info">
                                <div class="pull-md-left">
                                    <time class="meta fa-calendar" datetime="2022">2022 04</time>
                                </div><a class="button-link" href="https://www.bilibili.com/video/BV1E3411K7MR?spm_id_from=333.999.0.0">Read More</a>
                            </div>
                        </div>
                    </article>
                </div>
            </div> -->
            <!-- <div class="row row-30">
                <div class="col-lg-6">
                    <article class="thumbnail thumbnail-6">
                        <iframe controls src="//player.bilibili.com/player.html?aid=298558717&bvid=BV16F411u75p&cid=584858211&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=300 width=100%> </iframe>
                        <div class="caption">
                            <h4><a>Knowledge Graph Construction and Intelligent Question Answering for Low-Resource Scenarios</a></h4> <p class="text-dark-variant-2">Guilin Qi, Southeast University</p>
                            <div class="blog-info">
                                <div class="pull-md-left">
                                    <time class="meta fa-calendar" datetime="2022">2022 04</time>
                                </div><a class="button-link" href="https://www.bilibili.com/video/BV16F411u75p?spm_id_from=333.999.0.0">Read More</a>
                            </div>
                        </div>
                    </article>
                </div>
                <div class="col-lg-6">
                    <article class="thumbnail thumbnail-6">
                        <iframe controls src="//player.bilibili.com/player.html?aid=596041303&bvid=BV15B4y1m7AK&cid=584859935&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" height=300 width=100%> </iframe>
                        <div class="caption">
                            <h4><a>Technical practice of knowledge-driven multi-strategy and multi-modal question answering technology</a></h4> <p class="text-dark-variant-2">Haofen Wang, Tongji University</p>
                            <div class="blog-info">
                                <div class="pull-md-left">
                                    <time class="meta fa-calendar" datetime="2022">2022 04</time>
                                </div><a class="button-link" href="https://www.bilibili.com/video/BV15B4y1m7AK?spm_id_from=333.999.0.0">Read More</a>
                            </div>
                        </div>
                    </article>
                </div>
            </div> -->

        </div>

    </section>
    
    <!--Start section-->
    <section class="well well-sm well-inset-2 text-center">
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-xl-12">
                    <h1 class="font-weight-bold text-center">About Us</h1>
                    <p class="lead big">
                        In recent years, the laboratory has obtained tens of million yuan of scientific research resources input, including the Ministry of education, the National Natural Science Foundation of China, the major science and technology projects of the Shanghai Municipal Science and Technology Commission, the 211 special project of Fudan University, and more than 30 university enterprise cooperation projects. It has produced a large number of original and independent intellectual property rights research results and has developed "Fudan I robot for autonomous mental development" "Fuwa", "Aijia No.1", "Haibao robot", "Chinese and Western medicine health management robot" and other six generations of intelligent service robots.
                    </p>
                </div>
            </div>

            <div class="well well-sm well-inset-2 row justify-content-center">
                <div class="col-xl-12">
                    <h1 class="font-weight-bold text-center">Awards</h1>
                    <p class="lead big">
                        We have won the second prize of the 9th Shanghai Science and technology award for traditional Chinese medicine in 2019, the silver award of the international invention in 2018, the special award of the Romanian Academy of technology and Sciences, the grand prize in 2017 China International Industrial Exposition, the second prize of the technological invention of the Ministry of education, the second prize of Wu Wenjun's artificial intelligence science and technology progress award, the third prize of Shanghai Science and technology progress award, and the 2015 Suzhou science and technology leading talent.
                    </p>
                </div>
            </div>

    <!--Start section-->
    <!-- <section class="well well-sm well-inset-2 text-center text-lg-left">
        <div class="container">
            <h1 class="font-weight-bold text-center">Latest Publications</h1>
            <div class="row row-30">
                {% assign count=0%}
                {% for post in site.posts %}
                {% if post.type == 'paper' and count<3%}
                {% assign count = count | plus:1 %}
                <div class="col-lg-4">
                    <article class="thumbnail thumbnail-4"><img src="{{ BASE_PATH }}/images/paper_teser/{{ post.teser }}" width=400px height=200px  alt="">
                        <div class="caption">
                            <h4><a href="{{ post.url }}">{{ post.title }}</a></h4>
                            <p class="text-dark-variant-2">{{ post.author }}</p>
                            <div class="blog-info">
                                <div class="pull-md-left">
                                    <time class="meta fa-calendar" datetime="2019">{{ post.year }}
                                        {{ post.month }}</time>
                                </div><a class="button-link" href="{{ post.url }}">Read More</a>
                            </div>
                        </div>
                    </article>
                </div>
                {% endif %}
                {% endfor %}
            </div>
        </div>
    </section> -->
    <!--End section-->

    <!--Start section-->
    <section class="well well-sm well-inset-2 text-center">
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-xl-6">
                    <h1 class="font-weight-bold text-center">Collaboration</h1>
                </div>
            </div>
            <div class="row margin-1">
                <!--Owl Carousel-->
                <div class="owl-carousel" data-autoplay="true" data-items="1" data-md-items="2" data-sm-items="1"
                    data-lg-items="3" data-nav="true" data-margin="30" data-loop="true">
                    <blockquote class="quote-2"><img class="img-rounded" href="http://faet.fudan.edu.cn/main.htm" src="images/AETlogo.jpg" alt="">
                        <h6>
                            <cite>Academy for Engineering & Technology</cite>
                        </h6>
                        <p class="heading-6 font-italic font-base text-base">
                            <q>The Academy for Engineering & Technology (FAET) was established in January 2017. It aims to systematically integrate interdisciplinary and multidisciplinary cooperation based on the advantages of Fudan University's multidisciplinary basic research, aiming at the research and development of forward-looking, critical, and creative engineering and application technology-oriented to the major national needs.</q>
                        </p>
                    </blockquote>
                    <blockquote class="quote-2"><img class="img-rounded"  src="images/SCSlogo.jpg" alt="" href="http://www.cs.fudan.edu.cn/">
                        <h6>
                            <cite>School of Computer Science</cite>
                        </h6>
                        <p class="heading-6 font-italic font-base text-base">
                            <q>In 1975, Fudan University established the Department of computer science. In 2008, the school integrated the strength of computer science and technology and established the College of computer science and Technology. The national demonstrative software college established in 2002 and the national security college established in 2011 all rely on the college to carry out school running work.</q>
                        </p>
                    </blockquote>
                    <blockquote class="quote-2" ><img class="img-rounded" href="https://www.zte.com.cn/china/" src="images/ZTElogo.jpg" alt="">
                        <h6>
                            <cite >ZTE Corporation</cite>
                        </h6>
                        <p class="heading-6 font-italic font-base text-base">
                            <q>ZTE is the world's leading provider of integrated communication and information solutions. The company provides innovative technology and product solutions for telecom operators and government and enterprise customers in more than 160 countries and regions so that users all over the world can enjoy voice, data, multimedia, wireless broadband, and other all-around communication.</q>
                        </p>
                    </blockquote>
                   
                </div>
            </div>
        </div>
    </section>
    <!--End section-->

</main>

<!-- 添加JavaScript控制显示/隐藏功能 -->
<script>
    function toggleNewsVisibility() {
        var moreNewsSection = document.getElementById('more-news');
        var showMoreButton = document.getElementById('show-more-news');
        
        if (moreNewsSection.style.display === 'none') {
            moreNewsSection.style.display = 'block';
            showMoreButton.style.display = 'none';
        } else {
            moreNewsSection.style.display = 'none';
            showMoreButton.style.display = 'inline-block';
            // 平滑滚动到新闻部分
            document.getElementById('recent-news-container').scrollIntoView({behavior: 'smooth'});
        }
    }
</script>

<style>
    
    .card-header {
        background-color: transparent; /* 将卡片头部的背景设为透明 */
        border-bottom: none;         /* 移除卡片头部的下边框（如果有的话）*/
        padding-bottom: 10px;           /* 移除卡片头部的下内边距（以防万一）*/
        }

    /* 你可能也需要确保 card-title 没有额外的下边距或内边距 */
    .card-title {
        margin-bottom: 0; /* 移除 card-title 的下外边距 */
    }
    /* 美化按钮样式 */
    #show-more-news, #show-less-news {
    transition: all 0.3s ease;
    margin: 0px 0;
    box-shadow: 0 2px 5px rgba(0,0,0,0.1);

    font-weight: bold; 
    font-size: 1.1em; 
    border-radius: 25px;
    display: inline-block;
    }

    /* 悬停效果保持不变 */
    #show-more-news:hover, #show-less-news:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }

    /* 其他样式保持不变 */
    #more-news a:first-child {
        border-top: none !important;
        margin-top: 0 !important;
        padding-top: 0 !important;
    }

    .btn-outline-primary {
        color: #0c9ce4;
        background-color: transparent;
        background-image: none;
        border-color: #0c9ce4;
    }
    .btn-outline-primary:hover {
        color: #fff;
        background-color: #0c8bcb;
        border-color: #0c8bcb;
    }

    /* #show-more-news {
        display: inline-block;
    } */

    /* 修改数据集样式 */
    .dataset-card {
        background-color: #ffffff;
        border-radius: 12px;
        padding: 30px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.08);
        margin-bottom: 30px;
        transition: all 0.3s ease;
    }
    
    .dataset-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 6px 20px rgba(0,0,0,0.12);
    }
    
    .dataset-title {
        color: #333;
        font-weight: bold;
        font-size: 1.5rem;
    }
    
    .dataset-image {
        max-height: 400px;
        width: auto;
        display: inline-block;
    }
    
    /* 修改数据集联系方式样式 - 将邮箱地址改为黑色 */
    .dataset-contact a {
        color: #333333; /* 改为黑色 */
        text-decoration: none;
        display: inline-block;
        margin-right: 10px;
    }
    
    .dataset-contact a:hover {
        text-decoration: underline;
        color: #0c8bcb; /* 悬停时仍然可以变为蓝色以示交互 */
    }
    
    /* 确保按钮样式不会被上面的样式覆盖 */
    .dataset-contact a.btn {
        color: #ffffff !important; /* 按钮文字保持为白色 */
    }
    
    .dataset-contact a.btn:hover {
        text-decoration: none; /* 按钮悬停时不显示下划线 */
    }
    
    /* 调整按钮样式 */
    .dataset-contact .btn {
        padding: 8px 20px;
        font-weight: 600;
        margin-bottom: 0;
    }
    
    .btn-outline-dark {
        color: #343a40;
        border-color: #343a40;
    }
    
    .btn-outline-dark:hover {
        color: #fff;
        background-color: #343a40;
        border-color: #343a40;
    }
    
    /* 响应式调整 */
    @media (max-width: 767.98px) {
        .dataset-contact .col-md-5 {
            text-align: left;
            margin-top: 15px;
        }
        
        .dataset-contact .btn {
            margin-top: 10px;
            margin-right: 6px;
        }
    }

    /* 美化按钮样式 - 确保字体为白色 */
    .btn-paper, .btn-github {
        border-radius: 30px;
        padding: 10px 22px;
        font-weight: 600;
        font-size: 15px;
        transition: all 0.3s ease;
        margin-left: 10px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.08);
        border: none;
        letter-spacing: 0.4px;
        color: #ffffff !important; /* 强制设置字体颜色为白色 */
    }
    
    /* Paper按钮颜色 */
    .btn-paper {
        background: linear-gradient(135deg, #83b6df, #74b7ee);
    }
    
    .btn-paper:hover {
        background: linear-gradient(135deg, #6ca1cd, #5aa4e4);
        transform: translateY(-2px);
        box-shadow: 0 4px 10px rgba(51, 154, 240, 0.25);
    }
    
    /* GitHub按钮颜色 */
    .btn-github {
        background: linear-gradient(135deg, #6c757d, #495057);
    }
    
    .btn-github:hover {
        background: linear-gradient(135deg, #5a6268, #444b52);
        transform: translateY(-2px);
        box-shadow: 0 4px 10px rgba(108, 117, 125, 0.25);
    }
    
    /* 响应式调整保持不变 */
    @media (max-width: 767.98px) {
        .dataset-contact .col-md-5 {
            text-align: left;
            margin-top: 20px;
        }
        
        .btn-paper, .btn-github {
            margin-top: 5px;
            margin-left: 0;
            margin-right: 10px;
            display: inline-block;
        }
    }

    .dataset-venue {
        display: inline-block;
        background-color: #1E88E5;
        color: white;
        font-size: 0.9rem;
        font-weight: bold;
        padding: 3px 10px;
        border-radius: 4px;
        margin-right: 10px;
        margin-bottom: 5px;
        vertical-align: middle;
    }
    
    .dataset-name {
        display: inline-block;
        vertical-align: middle;
    }
    
    @media (max-width: 767px) {
        .dataset-venue {
            display: block;
            margin: 0 auto 10px auto;
            width: fit-content;
        }
    }
</style>



